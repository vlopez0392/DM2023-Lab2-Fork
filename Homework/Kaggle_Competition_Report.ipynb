{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition Report - Fall 2023 Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports \n",
    "import json \n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Loading the raw tweets_DM.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to create both a training and testing dataframe from the tweets_DM.json file. First let's load the raw tweet data into a python list and explore the possible attributes to consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Opening the tweets_DM.json file\n",
    "tweet_data = [];\n",
    "with open(\"./data/tweets_DM.json\" ,'r') as file:\n",
    "    for line in file:   \n",
    "        tweet_data.append(json.loads(line));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_score': 391,\n",
       " '_index': 'hashtag_tweets',\n",
       " '_source': {'tweet': {'hashtags': ['Snapchat'],\n",
       "   'tweet_id': '0x376b20',\n",
       "   'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}},\n",
       " '_crawldate': '2015-05-23 11:42:47',\n",
       " '_type': 'tweets'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length of the tweet_data list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867535"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Creating the testing and training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first big goal is to create a dataframe. We first systematically extract the relevant data from the .json file and we aim to create a .csv file for training and testing datasets simultaneously. We have identified the following attributes as relevant for our model. \n",
    "<ul>\n",
    "    <li>tweet_id </li>\n",
    "    <li>tweet_text</li>\n",
    "    <li>score</li>\n",
    "    <li>crawl_date</li>\n",
    "    <li>hashtag_text</li>\n",
    "    <li>target emotion (From emotion.csv)</li>\n",
    "</ul>\n",
    "\n",
    "We will read the *data_identification.csv* file and use the *identification* attribute to control where each data entry in the tweets_data list is directed to (either testing or training datasets). First, let's determine if any keys in the provided tweets json file have missing values. We design the feature counter for this purpose. While not too relevant right now, it may help us improve our data extraction procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_counter(tweet_data):\n",
    "    ##Get the keys \n",
    "    keys = tweet_data[0].keys()\n",
    "    \n",
    "    ##Count the features \n",
    "    feature_counts = dict.fromkeys(keys,0);\n",
    "    for tweet in tweet_data:\n",
    "        for key in keys:\n",
    "            if tweet[key]:\n",
    "                feature_counts[key] += 1;\n",
    "    return feature_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_score': 1867535,\n",
       " '_index': 1867535,\n",
       " '_source': 1867535,\n",
       " '_crawldate': 1867535,\n",
       " '_type': 1867535}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts = feature_counter(tweet_data);\n",
    "feature_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, each of the attributes above has some data in it. We are particulary interested in the source data since it contains the *tweet_id* and *tweet_text* attributes. These attributes are the cornerstone to improve the performance of our future model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate dictionary with featurest of interest\n",
    "def gen_tweet_dict(tweet_data):\n",
    "    ##Get the keys \n",
    "    keys = tweet_data[0].keys()\n",
    "    source_keys = tweet_data[0][\"_source\"][\"tweet\"].keys(); #['hashtags', 'tweet_id', 'text']\n",
    "\n",
    "    ##Declare temp variables to hold tweet_id, tweet_text, score, crawl_date, hashtag_text\n",
    "    tweet_id_key = ''; #String \n",
    "    tweet_text = '';   #String\n",
    "    score = 0;         #int\n",
    "    crawl_date = '';   #string\"\n",
    "    hashtag_text = ''; #List but cast it to string \n",
    "    hashtag = list();\n",
    "    \n",
    "    ##Create a dictionary with tweet_id as keys \n",
    "    tweet_dict = dict();\n",
    "\n",
    "    ##Fill the dictionary\n",
    "    for tweet in tweet_data:\n",
    "        for key in keys:\n",
    "            if key == \"_index\" or key == \"_type\":\n",
    "                continue;\n",
    "            else: \n",
    "                if key == \"_score\":\n",
    "                    score = np.int16(tweet[key]);\n",
    "                elif key == \"_crawldate\":\n",
    "                    crawl_date = tweet[key];    \n",
    "                elif key == \"_source\":\n",
    "                    for skey in source_keys:\n",
    "                        if skey == \"hashtags\":\n",
    "                            hashtag = tweet[key][\"tweet\"][skey];\n",
    "                            if len(hashtag) > 0: ##Tweet has hashtags\n",
    "                                hashtag_text = ' '.join(hashtag)\n",
    "                            else:\n",
    "                                hashtag_text = ' ';\n",
    "                        elif skey == \"tweet_id\":\n",
    "                            tweet_id_key = tweet[key][\"tweet\"][skey];\n",
    "                            tweet_dict[tweet_id_key] = {'tweet_id': tweet_id_key}\n",
    "                        elif skey == \"text\":\n",
    "                            tweet_text = str(tweet[key][\"tweet\"][skey])\n",
    "                            tweet_text = tweet_text.replace('\\r', \"\")\n",
    "        \n",
    "        ##Merge dictionaries\n",
    "        tweet_dict[tweet_id_key] |= {\"score\" : score, \"crawl_date\" : crawl_date, \"hashtag_text\": hashtag_text, \"tweet_text\":tweet_text};   \n",
    "    \n",
    "        ##Reset values\n",
    "        tweet_id_key = ''; tweet_text = ''; score = 0; crawl_date = ''; hashtag_text = ''; hashtag = list();\n",
    "\n",
    "    return tweet_dict;                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict = gen_tweet_dict(tweet_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some values in our dictionary and verify they are the same as in the tweets JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '0x3376ab',\n",
       " 'score': 491,\n",
       " 'crawl_date': '2016-12-25 02:16:36',\n",
       " 'hashtag_text': ' ',\n",
       " 'tweet_text': 'AND this British guy just paid for our dinner. Im feeling super <LH> rn'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dict['0x3376ab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '0x2e4bae',\n",
       " 'score': 696,\n",
       " 'crawl_date': '2016-08-18 13:43:49',\n",
       " 'hashtag_text': 'beautiful shahidkapoor Mirah',\n",
       " 'tweet_text': 'MIRAH RAJPUT is so luckyyyy!pretty pretty beauty beauty.#beautiful #shahidkapoor #Mirah'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dict['0x2e4bae'] ##Carriage return \\r example removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tweet_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must write to the *train.csv* amd *test.csv* files we created. We use the *data_identification.csv* file entries to determine where to write each dictionary in *tweet_dict*, specificially, each *tweet_id* entry in the *data_identification.csv* is used as key to index the *tweet_dict* dictionary and write to the appropriate csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_writer(tweet_dict):\n",
    "    ##First open the relevant csv files either in reading or writing mode\n",
    "    #Open the data_identification.csv in reading mode:\n",
    "    dataID_file = open(\"./data/data_identification.csv\", 'r');\n",
    "    dataID_reader = csv.reader(dataID_file);\n",
    "    next(dataID_reader); #['tweet_id', 'identification'] \n",
    "\n",
    "    #Open the train.csv and test.csv in writing mode\n",
    "    train_file = open(\"./train.csv\", 'w', newline='');\n",
    "    train_writer = csv.writer(train_file);\n",
    "    test_file  = open(\"./test.csv\", 'w', newline=''); \n",
    "    test_writer = csv.writer(test_file);\n",
    "\n",
    "    #Counter for each type of entry. We later verify that the sum of the counters is equal to the total number of examples\n",
    "    train_count = 0;\n",
    "    test_count  = 0;\n",
    "    data_count =  0;\n",
    "\n",
    "    ##Write the header to each file \n",
    "    header = ['tweet_id','tweet_text','hashtag_text','crawl_date','score'];\n",
    "    train_writer.writerow(header);\n",
    "    test_writer.writerow(header);\n",
    "\n",
    "    ##Write each dictionary entry into either train.csv or test.csv\n",
    "    keys = ['tweet_id','tweet_text','hashtag_text','crawl_date','score'];\n",
    "    for row in dataID_reader:\n",
    "        key = str(row[0]);\n",
    "        target_csv = str(row[1]);\n",
    "        tweet = tweet_dict[key]; \n",
    "\n",
    "        data = [];\n",
    "        for k in keys:\n",
    "            data.append(tweet[k]);\n",
    "\n",
    "        if target_csv == 'train':\n",
    "            train_writer.writerow(data);\n",
    "            train_count += 1;\n",
    "        elif target_csv == 'test':\n",
    "            test_writer.writerow(data);\n",
    "            test_count += 1;\n",
    "    \n",
    "    print(\"Processed \" + str(train_count) + \" training examples \");\n",
    "    print(\"Processed \" + str(test_count)  + \" test examples \")\n",
    "    print(\"Processed \" + str(train_count+test_count) + \" total examples\")\n",
    "    ##Close the files\n",
    "    dataID_file.close();\n",
    "    train_file.close();\n",
    "    test_file.close();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1455563 training examples \n",
      "Processed 411972 test examples \n",
      "Processed 1867535 total examples\n"
     ]
    }
   ],
   "source": [
    "CSV_writer(tweet_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to create our dataframes from the CSV files as we did in the Lab 2 tutorial. We first create the training dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/_jd53fqs7hn9l98yc6xmfh040000gn/T/ipykernel_96340/4049140103.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(\"./train.csv\",header=None, names=['tweet_id','tweet_text','hashtag_text','crawl_date','score'])\n"
     ]
    }
   ],
   "source": [
    "### Training data dataframe\n",
    "train_df = pd.read_csv(\"./train.csv\",header=None, names=['tweet_id','tweet_text','hashtag_text','crawl_date','score'])\n",
    "train_df.drop([0], inplace = True); #Drop the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>hashtag_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>Huge Respect🖒 @JohnnyVegasReal talking about l...</td>\n",
       "      <td></td>\n",
       "      <td>2015-01-17 03:07:03</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>spateradio app</td>\n",
       "      <td>2016-07-02 09:34:06</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td></td>\n",
       "      <td>2016-08-15 18:18:39</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a8830</td>\n",
       "      <td>Come join @ambushman27 on #PUBG while he striv...</td>\n",
       "      <td>PUBG GamersUnite twitch BeHealthy StayPositive...</td>\n",
       "      <td>2017-02-11 08:49:46</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x20b21d</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>strength bones God</td>\n",
       "      <td>2016-11-23 05:37:10</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                         tweet_text  \\\n",
       "1  0x29e452  Huge Respect🖒 @JohnnyVegasReal talking about l...   \n",
       "2  0x2b3819  Yoooo we hit all our monthly goals with the ne...   \n",
       "3  0x2a2acc  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...   \n",
       "4  0x2a8830  Come join @ambushman27 on #PUBG while he striv...   \n",
       "5  0x20b21d  @fanshixieen2014 Blessings!My #strength little...   \n",
       "\n",
       "                                        hashtag_text           crawl_date  \\\n",
       "1                                                     2015-01-17 03:07:03   \n",
       "2                                     spateradio app  2016-07-02 09:34:06   \n",
       "3                                                     2016-08-15 18:18:39   \n",
       "4  PUBG GamersUnite twitch BeHealthy StayPositive...  2017-02-11 08:49:46   \n",
       "5                                 strength bones God  2016-11-23 05:37:10   \n",
       "\n",
       "  score  \n",
       "1   809  \n",
       "2   808  \n",
       "3    16  \n",
       "4   768  \n",
       "5    70  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length of the training dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check the memory usage of the training dataframe and the datatypes of each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1455563 entries, 1 to 1455563\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   tweet_id      1455563 non-null  object\n",
      " 1   tweet_text    1455563 non-null  object\n",
      " 2   hashtag_text  1455559 non-null  object\n",
      " 3   crawl_date    1455563 non-null  object\n",
      " 4   score         1455563 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 632.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataframe is missing the *target_emotion* column which is crucial for our model to learn the emotion corresponding to each tweet. We then create a separate dataframe from the *emotion.csv* file and merge it to our training dataframe on the *tweet_id* column:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>target_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x34cd80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x33f099</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x2ae7b7</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x2408d4</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0x2b193b</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id target_emotion\n",
       "1   0x3140b1        sadness\n",
       "2   0x368b73        disgust\n",
       "3   0x296183   anticipation\n",
       "4   0x2bd6e1            joy\n",
       "5   0x2ee1dd   anticipation\n",
       "6   0x34cd80            joy\n",
       "7   0x33f099        sadness\n",
       "8   0x2ae7b7        sadness\n",
       "9   0x2408d4          trust\n",
       "10  0x2b193b        sadness"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df = pd.read_csv(\"./data/emotion.csv\",header=None, names=['tweet_id','target_emotion']);\n",
    "emotion_df.drop([0], inplace = True);\n",
    "emotion_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as with the training dataframe, let's check the length and memory usage of the emotion dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1455563 entries, 1 to 1455563\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   tweet_id        1455563 non-null  object\n",
      " 1   target_emotion  1455563 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 177.7 MB\n"
     ]
    }
   ],
   "source": [
    "emotion_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *memory usage* parameter set to *deep*, provides a better approximation of the memory usage of the system. Since the memory usage of our combined dataframes does not even reach 1 GB, we don't need to perform any memory reduction techniques. We proceed to merge our dataframes on the tweet_id column as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's cast the *tweet_id* column of each dataframe to string, reset the indices and sort the values in ascending order to make sure both columns have exactly the same values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Casting each column to string\n",
    "emotion_df['tweet_id'] = emotion_df['tweet_id'].astype('string')\n",
    "train_df['tweet_id'] = train_df['tweet_id'].astype('string')\n",
    "train_df['tweet_text'] = train_df['tweet_text'].astype('string')\n",
    "\n",
    "##Sorting and resetting the indices\n",
    "emotion_df = emotion_df.sort_values(by = [\"tweet_id\"]);\n",
    "emotion_df = emotion_df.reset_index(drop = True)\n",
    "\n",
    "train_df = train_df.sort_values(by = [\"tweet_id\"]);\n",
    "train_df = train_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>hashtag_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>BlackMirror</td>\n",
       "      <td>2015-05-16 10:36:47</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>twitch Destinybeta Destiny Destiny2 Destinythe...</td>\n",
       "      <td>2016-10-15 20:46:37</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td></td>\n",
       "      <td>2016-07-04 07:22:56</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>Confession NationalCandyCornDay CouldEatThemAl...</td>\n",
       "      <td>2016-04-16 12:53:40</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td></td>\n",
       "      <td>2017-04-22 17:50:28</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                         tweet_text  \\\n",
       "0  0x1c7f10   o m g Shut Up And Dance though #BlackMirror <LH>   \n",
       "1  0x1c7f11  On #twitch <LH> on the #Destinybeta #Destiny #...   \n",
       "2  0x1c7f14  A nice sunny wak this morning not many <LH> ar...   \n",
       "3  0x1c7f15  I'm one of those people who love candy corn......   \n",
       "4  0x1c7f16  @metmuseum What are these? They look like some...   \n",
       "\n",
       "                                        hashtag_text           crawl_date  \\\n",
       "0                                        BlackMirror  2015-05-16 10:36:47   \n",
       "1  twitch Destinybeta Destiny Destiny2 Destinythe...  2016-10-15 20:46:37   \n",
       "2                                                     2016-07-04 07:22:56   \n",
       "3  Confession NationalCandyCornDay CouldEatThemAl...  2016-04-16 12:53:40   \n",
       "4                                                     2017-04-22 17:50:28   \n",
       "\n",
       "  score  \n",
       "0   242  \n",
       "1   915  \n",
       "2   939  \n",
       "3   181  \n",
       "4   970  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>target_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id target_emotion\n",
       "0  0x1c7f10            joy\n",
       "1  0x1c7f11   anticipation\n",
       "2  0x1c7f14            joy\n",
       "3  0x1c7f15            joy\n",
       "4  0x1c7f16        disgust"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if both columns are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(train_df['tweet_id'].equals(emotion_df['tweet_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's merge both dataframes into a single training dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>hashtag_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "      <th>target_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>BlackMirror</td>\n",
       "      <td>2015-05-16 10:36:47</td>\n",
       "      <td>242</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>twitch Destinybeta Destiny Destiny2 Destinythe...</td>\n",
       "      <td>2016-10-15 20:46:37</td>\n",
       "      <td>915</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td></td>\n",
       "      <td>2016-07-04 07:22:56</td>\n",
       "      <td>939</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>Confession NationalCandyCornDay CouldEatThemAl...</td>\n",
       "      <td>2016-04-16 12:53:40</td>\n",
       "      <td>181</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td></td>\n",
       "      <td>2017-04-22 17:50:28</td>\n",
       "      <td>970</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1c7f19</td>\n",
       "      <td>Postive thinking is the only way to go followe...</td>\n",
       "      <td>LawOfAttraction ask receive dreambig</td>\n",
       "      <td>2017-08-19 23:08:46</td>\n",
       "      <td>678</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1c7f1a</td>\n",
       "      <td>Best Check I’ve had this year &lt;LH&gt; 👀🙏🙏</td>\n",
       "      <td></td>\n",
       "      <td>2015-10-08 03:43:33</td>\n",
       "      <td>314</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x1c7f1b</td>\n",
       "      <td>Have not eaten since yesterday &lt;LH&gt;</td>\n",
       "      <td></td>\n",
       "      <td>2017-06-06 17:38:13</td>\n",
       "      <td>232</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x1c7f1c</td>\n",
       "      <td>Glad to know that Ahmedabad has been declared ...</td>\n",
       "      <td>World</td>\n",
       "      <td>2015-03-02 22:19:51</td>\n",
       "      <td>870</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x1c7f1d</td>\n",
       "      <td>John 15:9 As the Father has loved me, so have ...</td>\n",
       "      <td>scriptureverse</td>\n",
       "      <td>2015-11-05 07:59:02</td>\n",
       "      <td>522</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                         tweet_text  \\\n",
       "0  0x1c7f10   o m g Shut Up And Dance though #BlackMirror <LH>   \n",
       "1  0x1c7f11  On #twitch <LH> on the #Destinybeta #Destiny #...   \n",
       "2  0x1c7f14  A nice sunny wak this morning not many <LH> ar...   \n",
       "3  0x1c7f15  I'm one of those people who love candy corn......   \n",
       "4  0x1c7f16  @metmuseum What are these? They look like some...   \n",
       "5  0x1c7f19  Postive thinking is the only way to go followe...   \n",
       "6  0x1c7f1a             Best Check I’ve had this year <LH> 👀🙏🙏   \n",
       "7  0x1c7f1b                Have not eaten since yesterday <LH>   \n",
       "8  0x1c7f1c  Glad to know that Ahmedabad has been declared ...   \n",
       "9  0x1c7f1d  John 15:9 As the Father has loved me, so have ...   \n",
       "\n",
       "                                        hashtag_text           crawl_date  \\\n",
       "0                                        BlackMirror  2015-05-16 10:36:47   \n",
       "1  twitch Destinybeta Destiny Destiny2 Destinythe...  2016-10-15 20:46:37   \n",
       "2                                                     2016-07-04 07:22:56   \n",
       "3  Confession NationalCandyCornDay CouldEatThemAl...  2016-04-16 12:53:40   \n",
       "4                                                     2017-04-22 17:50:28   \n",
       "5               LawOfAttraction ask receive dreambig  2017-08-19 23:08:46   \n",
       "6                                                     2015-10-08 03:43:33   \n",
       "7                                                     2017-06-06 17:38:13   \n",
       "8                                              World  2015-03-02 22:19:51   \n",
       "9                                     scriptureverse  2015-11-05 07:59:02   \n",
       "\n",
       "  score target_emotion  \n",
       "0   242            joy  \n",
       "1   915   anticipation  \n",
       "2   939            joy  \n",
       "3   181            joy  \n",
       "4   970        disgust  \n",
       "5   678   anticipation  \n",
       "6   314            joy  \n",
       "7   232   anticipation  \n",
       "8   870          trust  \n",
       "9   522            joy  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(emotion_df, on = 'tweet_id', how = 'left')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1455563 entries, 0 to 1455562\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   tweet_id        1455563 non-null  string\n",
      " 1   tweet_text      1455563 non-null  string\n",
      " 2   hashtag_text    1455559 non-null  object\n",
      " 3   crawl_date      1455563 non-null  object\n",
      " 4   score           1455563 non-null  object\n",
      " 5   target_emotion  1455563 non-null  object\n",
      "dtypes: object(4), string(2)\n",
      "memory usage: 719.6 MB\n"
     ]
    }
   ],
   "source": [
    "##Check the memory usage of the new train df\n",
    "train_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Lab #2, let's check how balanced are the classes in the emotion dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_emotion\n",
       "anger            39867\n",
       "anticipation    248935\n",
       "disgust         139101\n",
       "fear             63999\n",
       "joy             516017\n",
       "sadness         193437\n",
       "surprise         48729\n",
       "trust           205478\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.groupby(['target_emotion']).count()['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAE8CAYAAAAVCfobAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLXklEQVR4nO3dd3hUZf7//9cEkkkjlJCQxARC721BIOAC0lEREMuCK4RFLCCICLp8FAigSxEpKqJYgi3q6ooFpStRaSIQEMVIkKYEEJCEIsmY3L8//GW+M6SQwWRmGJ+P68oF5z733Oc97zk5M++cc+6xGGOMAAAAAACSJD9PBwAAAAAA3oQiCQAAAAAcUCQBAAAAgAOKJAAAAABwQJEEAAAAAA4okgAAAADAAUUSAAAAADigSAIAAAAABxRJAAAAAOCAIgkAUCYOHDggi8WipUuXejoUu65du6pr1672ZXfGuHTpUlksFh04cMDeFh8frxtuuKHcty1J69evl8Vi0fr1692yPQDwJRRJAODFCj5oF/ezefNmt8eUkpKiBQsWuH27nvTss896VfHnyJtjA4ArlcUYYzwdBACgaEuXLtXw4cM1ffp01a5du9D6Pn36qHr16m6N6YYbbtDu3budzpBIkjFGOTk58vf3V4UKFdwaU3EKziIVnE253BibNWum6tWru3RWJi8vTzabTVarVRaLRdIfZ5KaNWum5cuXl3qcy40tPz9fubm5CggIkJ8ffxMFAFdU9HQAAIBL69u3r9q2bevpMEpksVgUGBjo6TBK5I4Yz507p5CQEFWoUMGjxaKfn5/Xvx4A4K340xIA+ICCe23mzp2rRYsWqU6dOgoODlavXr10+PBhGWM0Y8YMxcbGKigoSP3799epU6cKjfPss8+qadOmslqtiomJ0ejRo3X69Gn7+q5du+rjjz/WwYMH7Zf8xcfHO8Vw8aVfn376qf7+978rJCREVapUUf/+/bVnzx6nPklJSbJYLMrIyFBiYqKqVKmiypUra/jw4Tp//nypcrBkyRLVrVtXQUFBateunb744oti8+QY49GjRzV8+HDFxsbKarUqOjpa/fv3t58pi4+P17fffqvU1FT7cy44Q1VwOWRqaqpGjRqlyMhIxcbGOq27+IybJK1evVqtWrVSYGCgmjRpovfee6/IfFzs4jFLiq24e5LeeecdtWnTRkFBQapevbr++c9/6ueff3bqk5iYqNDQUP38888aMGCAQkNDFRERoQkTJigvL6+YVwAAfAdnkgDgCpCVlaUTJ044tVksFoWHhzu1vfHGG8rNzdWYMWN06tQpzZkzR7feequ6deum9evX6+GHH1ZGRoaefvppTZgwQS+//LL9sUlJSZo2bZp69Oihe++9V+np6Vq8eLG2bt2qDRs2yN/fX4888oiysrL0008/af78+ZKk0NDQYuNeu3at+vbtqzp16igpKUm//fabnn76aXXq1Enbt2+3F1gFbr31VtWuXVszZ87U9u3b9eKLLyoyMlKzZ88uMT8vvfSS7r77bnXs2FHjxo3Tjz/+qBtvvFHVqlVTXFxciY8dNGiQvv32W40ZM0bx8fE6fvy41qxZo0OHDik+Pl4LFizQmDFjFBoaqkceeUSSVKNGDacxRo0apYiICE2ZMkXnzp0rcXt79+7VbbfdpnvuuUfDhg1TcnKybrnlFq1cuVI9e/Ys8bEXK01sjgou37z66qs1c+ZMHTt2TAsXLtSGDRu0Y8cOValSxd43Ly9PvXv3Vvv27TV37lytXbtWTz75pOrWrat7773XpTgB4IpjAABeKzk52Ugq8sdqtdr77d+/30gyERER5vTp0/b2SZMmGUmmZcuWxmaz2dsHDx5sAgICzIULF4wxxhw/ftwEBASYXr16mby8PHu/Z555xkgyL7/8sr3t+uuvN7Vq1SoUa0EMycnJ9rZWrVqZyMhIc/LkSXvbzp07jZ+fnxk6dKi9berUqUaS+de//uU05sCBA014eHiJOcrNzTWRkZGmVatWJicnx96+ZMkSI8l06dKl2Bh//fVXI8k88cQTJW6jadOmTuMUKHh9rrnmGvP7778XuW7//v32tlq1ahlJ5n//+5+9LSsry0RHR5vWrVvb2wryUdz2HMcsLrbPPvvMSDKfffaZMeb/5alZs2bmt99+s/dbvny5kWSmTJlibxs2bJiRZKZPn+40ZuvWrU2bNm0KbQsAfA2X2wHAFWDRokVas2aN08+KFSsK9bvllltUuXJl+3L79u0lSf/85z9VsWJFp/bc3Fz7ZVZr165Vbm6uxo0b53ST/8iRIxUWFqaPP/7Y5ZgzMzOVlpamxMREVatWzd7eokUL9ezZU5988kmhx9xzzz1Oy3//+9918uRJZWdnF7udr7/+WsePH9c999yjgIAAe3tiYqJTLooSFBSkgIAArV+/Xr/++mtpn1ohI0eOLPX9RzExMRo4cKB9OSwsTEOHDtWOHTt09OjRy47hUgryNGrUKKd7la6//no1atSoyNe4qNfjxx9/LLcYAcBbcLkdAFwB2rVrV6qJG2rWrOm0XFAkXHzJWUF7QWFw8OBBSVLDhg2d+gUEBKhOnTr29a4obkxJaty4sVatWmWf5KC4+KtWrWqPMywsrMTt1K9f36nd399fderUKTFGq9Wq2bNn68EHH1SNGjXUoUMH3XDDDRo6dKiioqIu8Qz/n6JmHixOvXr1Ct1v1KBBA0l/3DPlynZdUdLr0ahRI3355ZdObYGBgYqIiHBqq1q16p8qJgHgSsGZJADwIcWdzSiu3XjZt0B4Is5x48bphx9+0MyZMxUYGKjJkyercePG2rFjR6nHCAoKKtOYipq0QZJbJ03wlmncAcATKJIAAKpVq5YkKT093ak9NzdX+/fvt6+Xiv8AX9oxJen7779X9erVnc4iXa6C7ezdu9ep3Wazaf/+/aUao27dunrwwQe1evVq7d69W7m5uXryySft60v7nEsjIyOjUNH3ww8/SJJ9IouCM2iOMwtKKvKMXlm8Hunp6U6vMQD81VEkAQDUo0cPBQQE6KmnnnL6AP/SSy8pKytL119/vb0tJCREWVlZlxwzOjparVq10iuvvOL0YX/37t1avXq1rrvuujKJvW3btoqIiNBzzz2n3Nxce/vSpUsLFRkXO3/+vC5cuODUVrduXVWqVEk5OTn2tpCQkEuOVVpHjhzRsmXL7MvZ2dl69dVX1apVK/uldnXr1pUkff755/Z+586d0yuvvFJovNLG1rZtW0VGRuq5555zem4rVqzQnj17nF5jAPir454kALgCrFixQt9//32h9o4dO17yvpvSiIiI0KRJkzRt2jT16dNHN954o9LT0/Xss8/q6quv1j//+U973zZt2ujtt9/W+PHjdfXVVys0NFT9+vUrctwnnnhCffv2VUJCgkaMGGGfArxy5cpKSkr603FLf9x79Nhjj+nuu+9Wt27ddNttt2n//v1KTk6+ZG5++OEHde/eXbfeequaNGmiihUratmyZTp27Jj+8Y9/OD3nxYsX67HHHlO9evUUGRmpbt26XVa8DRo00IgRI7R161bVqFFDL7/8so4dO6bk5GR7n169eqlmzZoaMWKEJk6cqAoVKujll19WRESEDh065DReaWPz9/fX7NmzNXz4cHXp0kWDBw+2TwEeHx+vBx544LKeDwD4IookALgCTJkypcj20hQCpZWUlKSIiAg988wzeuCBB1StWjXddddd+s9//iN/f397v1GjRiktLU3JycmaP3++atWqVWyR1KNHD61cuVJTp07VlClT5O/vry5dumj27NkuTXZwKXfddZfy8vL0xBNPaOLEiWrevLk+/PBDTZ48ucTHxcXFafDgwVq3bp1ee+01VaxYUY0aNdJ///tfDRo0yN5vypQpOnjwoObMmaMzZ86oS5cul10k1a9fX08//bQmTpyo9PR01a5dW2+//bZ69+5t7+Pv769ly5Zp1KhRmjx5sqKiojRu3DhVrVpVw4cPdxrPldgSExMVHBysWbNm6eGHH1ZISIgGDhyo2bNnO31HEgD81VmMt921CwAAAAAexD1JAAAAAOCAIgkAAAAAHFAkAQAAAIADiiQAAAAAcECRBAAAAAAOKJIAAAAAwIHPf09Sfn6+jhw5okqVKslisXg6HAAAAAAeYozRmTNnFBMTIz+/4s8X+XyRdOTIEcXFxXk6DAAAAABe4vDhw4qNjS12vc8XSZUqVZL0RyLCwsI8HI13sdlsWr16tXr16iV/f39Ph+PTyLV7kGf3IM/uQ67dgzy7B3l2H3JdvOzsbMXFxdlrhOL4fJFUcIldWFgYRdJFbDabgoODFRYWxi9QOSPX7kGe3YM8uw+5dg/y7B7k2X3I9aVd6jYcJm4AAAAAAAcUSQAAAADggCIJAAAAABxQJAEAAACAA4okAAAAAHBAkQQAAAAADiiSAAAAAMCBR4ukxYsXq0WLFvbvMEpISNCKFSvs67t27SqLxeL0c88993gwYgAAAAC+zqNfJhsbG6tZs2apfv36MsbolVdeUf/+/bVjxw41bdpUkjRy5EhNnz7d/pjg4GBPhQsA8HHx//7Y0yE4sVYwmtNOapa0Sjl5JX/xobscmHW9p0MAgHLn0SKpX79+TsuPP/64Fi9erM2bN9uLpODgYEVFRXkiPAAAAAB/QR4tkhzl5eXpnXfe0blz55SQkGBvf+ONN/T6668rKipK/fr10+TJk0s8m5STk6OcnBz7cnZ2tiTJZrPJZrOV3xO4AhXkg7yUP3LtHuTZPXw5z9YKxtMhOLH6Gad/vYEvvu6+vE97E/LsPuS6eKXNicUY49Ej7zfffKOEhARduHBBoaGhSklJ0XXXXSdJWrJkiWrVqqWYmBjt2rVLDz/8sNq1a6f33nuv2PGSkpI0bdq0Qu0pKSlcqgcAAAD8hZ0/f15DhgxRVlaWwsLCiu3n8SIpNzdXhw4dUlZWlt599129+OKLSk1NVZMmTQr1/fTTT9W9e3dlZGSobt26RY5X1JmkuLg4nThxosRE/BXZbDatWbNGPXv2lL+/v6fD8Wnk2j3Is3v4cp6bJa3ydAhOrH5GM9rma/LXfsrJ9457knYn9fZ0CGXOl/dpb0Ke3YdcFy87O1vVq1e/ZJHk8cvtAgICVK9ePUlSmzZttHXrVi1cuFDPP/98ob7t27eXpBKLJKvVKqvVWqjd39+fnaQY5MZ9yLV7kGf38MU8e8vkCBfLybd4TWy+9po78sV92huRZ/ch14WVNh9e9z1J+fn5TmeCHKWlpUmSoqOj3RgRAAAAgL8Sj55JmjRpkvr27auaNWvqzJkzSklJ0fr167Vq1Srt27fPfn9SeHi4du3apQceeECdO3dWixYtPBk2AAAAAB/m0SLp+PHjGjp0qDIzM1W5cmW1aNFCq1atUs+ePXX48GGtXbtWCxYs0Llz5xQXF6dBgwbp0Ucf9WTIAAAAAHycR4ukl156qdh1cXFxSk1NdWM0AAAAAOCF9yQBAAAAgCdRJAEAAACAA4okAAAAAHBAkQQAAAAADiiSAAAAAMABRRIAAAAAOKBIAgAAAAAHFEkAAAAA4IAiCQAAAAAcUCQBAAAAgAOKJAAAAABwQJEEAAAAAA4okgAAAADAAUUSAAAAADigSAIAAAAABxRJAAAAAOCAIgkAAAAAHFAkAQAAAIADiiQAAAAAcECRBAAAAAAOPFokLV68WC1atFBYWJjCwsKUkJCgFStW2NdfuHBBo0ePVnh4uEJDQzVo0CAdO3bMgxEDAAAA8HUeLZJiY2M1a9Ysbdu2TV9//bW6deum/v3769tvv5UkPfDAA/roo4/0zjvvKDU1VUeOHNFNN93kyZABAAAA+LiKntx4v379nJYff/xxLV68WJs3b1ZsbKxeeuklpaSkqFu3bpKk5ORkNW7cWJs3b1aHDh08ETIAAAAAH+fRIslRXl6e3nnnHZ07d04JCQnatm2bbDabevToYe/TqFEj1axZU5s2bSq2SMrJyVFOTo59OTs7W5Jks9lks9nK90lcYQryQV7KH7l2D/LsHr6cZ2sF4+kQnFj9jNO/3sAXX3df3qe9CXl2H3JdvNLmxGKM8eiR95tvvlFCQoIuXLig0NBQpaSk6LrrrlNKSoqGDx/uVPBIUrt27XTttddq9uzZRY6XlJSkadOmFWpPSUlRcHBwuTwHAAAAAN7v/PnzGjJkiLKyshQWFlZsP4+fSWrYsKHS0tKUlZWld999V8OGDVNqaupljzdp0iSNHz/evpydna24uDj16tWrxET8FdlsNq1Zs0Y9e/aUv7+/p8PxaeTaPcize/hynpslrfJ0CE6sfkYz2uZr8td+ysm3eDocSdLupN6eDqHM+fI+7U3Is/uQ6+IVXGV2KR4vkgICAlSvXj1JUps2bbR161YtXLhQt912m3Jzc3X69GlVqVLF3v/YsWOKiooqdjyr1Sqr1Vqo3d/fn52kGOTGfci1e5Bn9/DFPOfkeUchcrGcfIvXxOZrr7kjX9ynvRF5dh9yXVhp8+F135OUn5+vnJwctWnTRv7+/lq3bp19XXp6ug4dOqSEhAQPRggAAADAl3n0TNKkSZPUt29f1axZU2fOnFFKSorWr1+vVatWqXLlyhoxYoTGjx+vatWqKSwsTGPGjFFCQgIz2wEAAAAoNx4tko4fP66hQ4cqMzNTlStXVosWLbRq1Sr17NlTkjR//nz5+flp0KBBysnJUe/evfXss896MmQAAAAAPs6jRdJLL71U4vrAwEAtWrRIixYtclNEAAAAAP7qvO6eJAAAAADwJIokAAAAAHBAkQQAAAAADiiSAAAAAMABRRIAAAAAOKBIAgAAAAAHFEkAAAAA4IAiCQAAAAAcUCQBAAAAgAOKJAAAAABwQJEEAAAAAA4okgAAAADAAUUSAAAAADigSAIAAAAABy4XSYcPH9ZPP/1kX/7qq680btw4LVmypEwDAwAAAABPcLlIGjJkiD777DNJ0tGjR9WzZ0999dVXeuSRRzR9+vQyDxAAAAAA3MnlImn37t1q166dJOm///2vmjVrpo0bN+qNN97Q0qVLyzo+AAAAAHArl4skm80mq9UqSVq7dq1uvPFGSVKjRo2UmZlZttEBAAAAgJu5XCQ1bdpUzz33nL744gutWbNGffr0kSQdOXJE4eHhZR4gAAAAALiTy0XS7Nmz9fzzz6tr164aPHiwWrZsKUn68MMP7ZfhAQAAAMCVyuUiqWvXrjpx4oROnDihl19+2d5+11136bnnnnNprJkzZ+rqq69WpUqVFBkZqQEDBig9Pb3Q9iwWi9PPPffc42rYAAAAAFAql/U9ScYYbdu2Tc8//7zOnDkjSQoICFBwcLBL46Smpmr06NHavHmz1qxZI5vNpl69euncuXNO/UaOHKnMzEz7z5w5cy4nbAAAAAC4pIquPuDgwYPq06ePDh06pJycHPXs2VOVKlXS7NmzlZOT49LZpJUrVzotL126VJGRkdq2bZs6d+5sbw8ODlZUVJSroQIAAACAy1wuku6//361bdtWO3fudJqoYeDAgRo5cuSfCiYrK0uSVK1aNaf2N954Q6+//rqioqLUr18/TZ48udizVjk5OcrJybEvZ2dnS/pjVj6bzfan4vM1BfkgL+WPXLsHeXYPX86ztYLxdAhOrH7G6V9v4Iuvuy/v096EPLsPuS5eaXNiMca4dOQNDw/Xxo0b1bBhQ1WqVEk7d+5UnTp1dODAATVp0kTnz5+/rIDz8/N144036vTp0/ryyy/t7UuWLFGtWrUUExOjXbt26eGHH1a7du303nvvFTlOUlKSpk2bVqg9JSXF5csBAQAAAPiO8+fPa8iQIcrKylJYWFix/Vw+k5Sfn6+8vLxC7T/99JMqVark6nB2o0eP1u7du50KJOmPCSEKNG/eXNHR0erevbv27dununXrFhpn0qRJGj9+vH05OztbcXFx6tWrV4mJ+Cuy2Wxas2aNevbsKX9/f0+H49PItXuQZ/fw5Tw3S1rl6RCcWP2MZrTN1+Sv/ZSTb/F0OJKk3Um9PR1CmfPlfdqbkGf3IdfFK7jK7FJcLpJ69eqlBQsWaMmSJZIki8Wis2fPaurUqbruuutcHU6SdN9992n58uX6/PPPFRsbW2Lf9u3bS5IyMjKKLJKsVqv9y24d+fv7s5MUg9y4D7l2D/LsHr6Y55w87yhELpaTb/Ga2HztNXfki/u0NyLP7kOuCyttPlwukp588kn17t1bTZo00YULFzRkyBDt3btX1atX15tvvunSWMYYjRkzRsuWLdP69etVu3btSz4mLS1NkhQdHe1q6AAAAABwSS4XSbGxsdq5c6fefvtt7dy5U2fPntWIESN0++23KygoyKWxRo8erZSUFH3wwQeqVKmSjh49KkmqXLmygoKCtG/fPqWkpOi6665TeHi4du3apQceeECdO3dWixYtXA0dAAAAAC7J5SJJkipWrKjbb79dt99++5/a+OLFiyX98YWxjpKTk5WYmKiAgACtXbtWCxYs0Llz5xQXF6dBgwbp0Ucf/VPbBQAAAIDiuFwkzZw5UzVq1NC//vUvp/aXX35Zv/zyix5++OFSj3WpifXi4uKUmprqaogAAAAAcNn8XH3A888/r0aNGhVqb9q0qUtfJAsAAAAA3sjlIuno0aNFTpoQERGhzMzMMgkKAAAAADzF5SIpLi5OGzZsKNS+YcMGxcTElElQAAAAAOApLt+TNHLkSI0bN042m03dunWTJK1bt04PPfSQHnzwwTIPEAAAAADcyeUiaeLEiTp58qRGjRql3NxcSVJgYKAefvhhTZo0qcwDBAAAAAB3crlIslgsmj17tiZPnqw9e/YoKChI9evXl9VqLY/4AAAAAMCtLut7kiQpNDRUV199dVnGAgAAAAAe53KRdO7cOc2aNUvr1q3T8ePHlZ+f77T+xx9/LLPgAAAAAMDdXC6S7rzzTqWmpuqOO+5QdHS0LBZLecQFAAAAAB7hcpG0YsUKffzxx+rUqVN5xAMAAAAAHuXy9yRVrVpV1apVK49YAAAAAMDjXC6SZsyYoSlTpuj8+fPlEQ8AAAAAeJTLl9s9+eST2rdvn2rUqKH4+Hj5+/s7rd++fXuZBQcAAAAA7uZykTRgwIByCAMAAAAAvIPLRdLUqVPLIw4AAAAA8Aou35MEAAAAAL7M5TNJeXl5mj9/vv773//q0KFDys3NdVp/6tSpMgsOAAAAANzN5TNJ06ZN07x583TbbbcpKytL48eP10033SQ/Pz8lJSWVQ4gAAAAA4D4uF0lvvPGGXnjhBT344IOqWLGiBg8erBdffFFTpkzR5s2byyNGAAAAAHAbl4uko0ePqnnz5pKk0NBQZWVlSZJuuOEGffzxx2UbHQAAAAC4mctFUmxsrDIzMyVJdevW1erVqyVJW7duldVqdWmsmTNn6uqrr1alSpUUGRmpAQMGKD093anPhQsXNHr0aIWHhys0NFSDBg3SsWPHXA0bAAAAAErF5SJp4MCBWrdunSRpzJgxmjx5surXr6+hQ4fqX//6l0tjpaamavTo0dq8ebPWrFkjm82mXr166dy5c/Y+DzzwgD766CO98847Sk1N1ZEjR3TTTTe5GjYAAAAAlIrLs9vNmjXL/v/bbrtNtWrV0saNG1W/fn3169fPpbFWrlzptLx06VJFRkZq27Zt6ty5s7KysvTSSy8pJSVF3bp1kyQlJyercePG2rx5szp06OBq+AAAAABQIpeLpM8//1wdO3ZUxYp/PLRDhw7q0KGDfv/9d33++efq3LnzZQdTcH9TtWrVJEnbtm2TzWZTjx497H0aNWqkmjVratOmTUUWSTk5OcrJybEvZ2dnS5JsNptsNttlx+aLCvJBXsofuXYP8uwevpxnawXj6RCcWP2M07/ewBdfd1/ep70JeXYfcl280ubEYoxx6chboUIFZWZmKjIy0qn95MmTioyMVF5enivD2eXn5+vGG2/U6dOn9eWXX0qSUlJSNHz4cKeiR5LatWuna6+9VrNnzy40TlJSkqZNm1aoPSUlRcHBwZcVGwAAAIAr3/nz5zVkyBBlZWUpLCys2H4un0kyxshisRRqP3nypEJCQlwdzm706NHavXu3vUC6XJMmTdL48ePty9nZ2YqLi1OvXr1KTMRfkc1m05o1a9SzZ0/5+/t7OhyfRq7dgzy7hy/nuVnSKk+H4MTqZzSjbb4mf+2nnPzC772esDupt6dDKHO+vE97E/LsPuS6eAVXmV1KqYukgskSLBaLEhMTnWayy8vL065du9SxY0cXw/zDfffdp+XLl+vzzz9XbGysvT0qKkq5ubk6ffq0qlSpYm8/duyYoqKiihzLarUWOcuev78/O0kxyI37kGv3IM/u4Yt5zsnzjkLkYjn5Fq+Jzddec0e+uE97I/LsPuS6sNLmo9RFUuXKlSX9cSapUqVKCgoKsq8LCAhQhw4dNHLkSJeCNMZozJgxWrZsmdavX6/atWs7rW/Tpo38/f21bt06DRo0SJKUnp6uQ4cOKSEhwaVtAQAAAEBplLpISk5OliTFx8drwoQJf+rSugKjR49WSkqKPvjgA1WqVElHjx6V9EdBFhQUpMqVK2vEiBEaP368qlWrprCwMI0ZM0YJCQnMbAcAAACgXLh8T9JDDz0kx7keDh48qGXLlqlJkybq1auXS2MtXrxYktS1a1en9uTkZCUmJkqS5s+fLz8/Pw0aNEg5OTnq3bu3nn32WVfDBgAAAIBScblI6t+/v2666Sbdc889On36tNq1a6eAgACdOHFC8+bN07333lvqsUozsV5gYKAWLVqkRYsWuRoqAAAAALjMz9UHbN++XX//+98lSe+++66ioqJ08OBBvfrqq3rqqafKPEAAAAAAcCeXi6Tz58+rUqVKkqTVq1frpptukp+fnzp06KCDBw+WeYAAAAAA4E4uF0n16tXT+++/r8OHD2vVqlX2+5COHz/O9xABAAAAuOK5XCRNmTJFEyZMUHx8vNq3b2+finv16tVq3bp1mQcIAAAAAO7k8sQNN998s6655hplZmaqZcuW9vbu3btr4MCBZRocAAAAALiby0WSJEVFRSkqKsqprV27dmUSEAAAAAB4kstF0rlz5zRr1iytW7dOx48fV35+vtP6H3/8scyCAwAAAAB3c7lIuvPOO5Wamqo77rhD0dHRslgs5REXAAAAAHiEy0XSihUr9PHHH6tTp07lEQ8AAAAAeJTLs9tVrVpV1apVK49YAAAAAMDjXC6SZsyYoSlTpuj8+fPlEQ8AAAAAeJTLl9s9+eST2rdvn2rUqKH4+Hj5+/s7rd++fXuZBQdcrvh/f+zpEJxYKxjNaSc1S1qlnDzvuI/vwKzrPR0CAACAV3K5SBowYEA5hAEAAAAA3sHlImnq1KnlEQcAAAAAeAWX70kCAAAAAF9WqjNJ1apV0w8//KDq1auratWqJX430qlTp8osOAAAAABwt1IVSfPnz1elSpUkSQsWLCjPeAAAAADAo0pVJA0bNqzI/wMAAACAr+GeJAAAAABwQJEEAAAAAA48WiR9/vnn6tevn2JiYmSxWPT+++87rU9MTJTFYnH66dOnj2eCBQAAAPCXUKoiadeuXcrPzy/zjZ87d04tW7bUokWLiu3Tp08fZWZm2n/efPPNMo8DAAAAAAqUauKG1q1bKzMzU5GRkapTp462bt2q8PDwP73xvn37qm/fviX2sVqtioqK+tPbAgAAAIDSKFWRVKVKFe3fv1+RkZE6cOBAuZxVKs769esVGRmpqlWrqlu3bnrsscdKLNBycnKUk5NjX87OzpYk2Ww22Wy2co/3SlKQD1/Mi7WC8XQITqx+xulfb+CLr7sv79PexJfzzLHj0nzxdfflfdqbkGf3IdfFK21OLMaYSx5577rrLr366quKjo7WoUOHFBsbqwoVKhTZ98cff3Qt0oJALBYtW7ZMAwYMsLe99dZbCg4OVu3atbVv3z793//9n0JDQ7Vp06Zit5+UlKRp06YVak9JSVFwcPBlxQYAAADgynf+/HkNGTJEWVlZCgsLK7ZfqYokSVq5cqUyMjI0duxYTZ8+3f7lshe7//77Lyvgooqki/3444+qW7eu1q5dq+7duxfZp6gzSXFxcTpx4kSJifgrstlsWrNmjXr27Cl/f39Ph1OmmiWt8nQITqx+RjPa5mvy137Kybd4OhxJ0u6k3p4Oocz58j7tTXw5zxw7Lo1jBy4XeXYfcl287OxsVa9e/ZJFUqkut5Nkn1Vu27Ztuv/++4stkspTnTp1VL16dWVkZBRbJFmtVlmt1kLt/v7+7CTF8MXc5OR5x4eJi+XkW7wmNl97zR354j7tjXwxz97y+3kxjh3u4Yv7tDciz+5DrgsrbT5KXSQVSE5Otv//p59+kiTFxsa6Osxl+emnn3Ty5ElFR0e7ZXsAAAAA/npc/p6k/Px8TZ8+XZUrV1atWrVUq1YtValSRTNmzHB5QoezZ88qLS1NaWlpkqT9+/crLS1Nhw4d0tmzZzVx4kRt3rxZBw4c0Lp169S/f3/Vq1dPvXv73ql+AAAAAN7B5TNJjzzyiF566SXNmjVLnTp1kiR9+eWXSkpK0oULF/T444+Xeqyvv/5a1157rX15/PjxkqRhw4Zp8eLF2rVrl1555RWdPn1aMTEx6tWrl2bMmFHk5XQAAACAJ8T/+2NPh+DEWsFoTrs/7rP0lkt1D8y63tMhuMTlIumVV17Riy++qBtvvNHe1qJFC1111VUaNWqUS0VS165dVdK8EatWedcNtAAAAAB8n8uX2506dUqNGjUq1N6oUSOdOnWqTIICAAAAAE9xuUhq2bKlnnnmmULtzzzzjFq2bFkmQQEAAACAp7h8ud2cOXN0/fXXa+3atUpISJAkbdq0SYcPH9Ynn3xS5gECAAAAgDu5XCR16dJFP/zwgxYtWqTvv/9eknTTTTdp1KhRiomJKfMAAQCA7/GmG925yR3AxVwukiQpJibGpQkaAAAAAOBK4fI9SQAAAADgyyiSAAAAAMABRRIAAAAAOKBIAgAAAAAHlzVxQ4ETJ05oy5YtysvL09VXX63o6OiyigsAAAAAPOKyi6T//e9/GjFihBo0aCCbzab09HQtWrRIw4cPL8v4AAAAAMCtSn253dmzZ52Wp02bpq+++kpfffWVduzYoXfeeUePPPJImQcIAAAAAO5U6iKpTZs2+uCDD+zLFStW1PHjx+3Lx44dU0BAQNlGBwAAAABuVurL7VatWqXRo0dr6dKlWrRokRYuXKjbbrtNeXl5+v333+Xn56elS5eWY6gAAAAAUP5KXSTFx8fr448/1ptvvqkuXbpo7NixysjIUEZGhvLy8tSoUSMFBgaWZ6wAAAAAUO5cngJ88ODB2rp1q3bu3KmuXbsqPz9frVq1okACAAAA4BNcmt3uk08+0Z49e9SyZUu9+OKLSk1N1e23366+fftq+vTpCgoKKq84AQAAAMAtSn0m6cEHH9Tw4cO1detW3X333ZoxY4a6dOmi7du3KzAwUK1bt9aKFSvKM1YAAAAAKHelLpKWLl2qTz75RG+99Za2bt2q1157TZIUEBCgGTNm6L333tN//vOfcgsUAAAAANyh1EVSSEiI9u/fL0k6fPhwoXuQmjRpoi+++KJsowMAAAAANyt1kTRz5kwNHTpUMTEx6tKli2bMmPGnN/7555+rX79+iomJkcVi0fvvv++03hijKVOmKDo6WkFBQerRo4f27t37p7cLAAAAAMUpdZF0++236/Dhw/rggw904MAB9e/f/09v/Ny5c2rZsqUWLVpU5Po5c+boqaee0nPPPactW7YoJCREvXv31oULF/70tgEAAACgKC7NbhceHq7w8PAy23jfvn3Vt2/fItcZY7RgwQI9+uij9oLs1VdfVY0aNfT+++/rH//4R5nFAQAAAAAFXCqS3Gn//v06evSoevToYW+rXLmy2rdvr02bNhVbJOXk5CgnJ8e+nJ2dLUmy2Wyy2WzlG/QVpiAfvpgXawXj6RCcWP2M07/ewBdfd1/ep72JL+eZY8elldXr7k259uU8exOOHe7DPl280sZhMcZ4RfYsFouWLVumAQMGSJI2btyoTp066ciRI4qOjrb3u/XWW2WxWPT2228XOU5SUpKmTZtWqD0lJUXBwcHlEjsAAAAA73f+/HkNGTJEWVlZCgsLK7af155JulyTJk3S+PHj7cvZ2dmKi4tTr169SkzEX5HNZtOaNWvUs2dP+fv7ezqcMtUsaZWnQ3Bi9TOa0TZfk7/2U06+xdPhSJJ2J/X2dAhlzpf3aW/iy3nm2HFpZXXs8KZc+3KevQnHDvdhny5ewVVml+K1RVJUVJQk6dixY05nko4dO6ZWrVoV+zir1Sqr1Vqo3d/f3+d+IcuKL+YmJ887DggXy8m3eE1sZfWax//74zIZpyxYKxjNaSe1fvxTr8nzgVnXezqEcsOxw3188djhLc/HkS/m2Rtx7HAf9unCShtHqWe3c7fatWsrKipK69ats7dlZ2dry5YtSkhI8GBkAAAAAHyZR88knT17VhkZGfbl/fv3Ky0tTdWqVVPNmjU1btw4PfbYY6pfv75q166tyZMnKyYmxn7fEgAAAACUNY8WSV9//bWuvfZa+3LBvUTDhg3T0qVL9dBDD+ncuXO66667dPr0aV1zzTVauXKlAgMDPRUyAAAAAB/n0SKpa9euKmlyPYvFounTp2v69OlujAoAAADAX5nX3pMEAAAAAJ5AkQQAAAAADiiSAAAAAMABRRIAAAAAOKBIAgAAAAAHFEkAAAAA4IAiCQAAAAAcUCQBAAAAgAOKJAAAAABwQJEEAAAAAA4okgAAAADAAUUSAAAAADigSAIAAAAABxRJAAAAAOCAIgkAAAAAHFAkAQAAAIADiiQAAAAAcECRBAAAAAAOKJIAAAAAwAFFEgAAAAA48OoiKSkpSRaLxemnUaNGng4LAAAAgA+r6OkALqVp06Zau3atfbliRa8PGQAAAMAVzOsrjooVKyoqKsrTYQAAAAD4i/D6Imnv3r2KiYlRYGCgEhISNHPmTNWsWbPY/jk5OcrJybEvZ2dnS5JsNptsNlu5x3slKciHL+bFWsF4OgQnVj/j9K83KKvX3Zty7ct59iYcO9zHl/dpb8q1L+fZm3DscB/26eKVNg6LMcZ7sneRFStW6OzZs2rYsKEyMzM1bdo0/fzzz9q9e7cqVapU5GOSkpI0bdq0Qu0pKSkKDg4u75ABAAAAeKnz589ryJAhysrKUlhYWLH9vLpIutjp06dVq1YtzZs3TyNGjCiyT1FnkuLi4nTixIkSE/FXZLPZtGbNGvXs2VP+/v6eDqdMNUta5ekQnFj9jGa0zdfkr/2Uk2/xdDiSpN1JvctkHG/KtS/n2Ztw7HAfX96nvSnXvpxnb8Kxw33Yp4uXnZ2t6tWrX7JI8vrL7RxVqVJFDRo0UEZGRrF9rFarrFZroXZ/f3+f+4UsK76Ym5w87zggXCwn3+I1sZXVa+4tz8eRL+bZG3HscB9f3Ke95fk48sU8eyOOHe7DPl1YaeO4ooqks2fPat++fbrjjjs8HQoAuFX8vz/2dAh21gpGc9r98ZdTb3nzPTDrek+HAADwIV79PUkTJkxQamqqDhw4oI0bN2rgwIGqUKGCBg8e7OnQAAAAAPgorz6T9NNPP2nw4ME6efKkIiIidM0112jz5s2KiIjwdGgAAAAAfJRXF0lvvfWWp0MAAAAA8Bfj1ZfbAQAAAIC7USQBAAAAgAOKJAAAAABw4NX3JAEAAODy8fUBJePrA1AcziQBAAAAgAOKJAAAAABwQJEEAAAAAA64J8nNuDa4ZFwbDAAAAE/jTBIAAAAAOKBIAgAAAAAHFEkAAAAA4IAiCQAAAAAcUCQBAAAAgAOKJAAAAABwQJEEAAAAAA4okgAAAADAAUUSAAAAADigSAIAAAAABxRJAAAAAOCAIgkAAAAAHFwRRdKiRYsUHx+vwMBAtW/fXl999ZWnQwIAAADgo7y+SHr77bc1fvx4TZ06Vdu3b1fLli3Vu3dvHT9+3NOhAQAAAPBBXl8kzZs3TyNHjtTw4cPVpEkTPffccwoODtbLL7/s6dAAAAAA+KCKng6gJLm5udq2bZsmTZpkb/Pz81OPHj20adOmIh+Tk5OjnJwc+3JWVpYk6dSpU7LZbOUbcClU/P2cp0Owq5hvdP58vira/JSXb/F0OJKkkydPlsk43pRniVy7C3l2D/LsPuTaPcize5Bn9/HlXP9ZZ86ckSQZY0rsZzGX6uFBR44c0VVXXaWNGzcqISHB3v7QQw8pNTVVW7ZsKfSYpKQkTZs2zZ1hAgAAALiCHD58WLGxscWu9+ozSZdj0qRJGj9+vH05Pz9fp06dUnh4uCwW76ikvUV2drbi4uJ0+PBhhYWFeTocn0au3YM8uwd5dh9y7R7k2T3Is/uQ6+IZY3TmzBnFxMSU2M+ri6Tq1aurQoUKOnbsmFP7sWPHFBUVVeRjrFarrFarU1uVKlXKK0SfEBYWxi+Qm5Br9yDP7kGe3Ydcuwd5dg/y7D7kumiVK1e+ZB+vnrghICBAbdq00bp16+xt+fn5WrdundPldwAAAABQVrz6TJIkjR8/XsOGDVPbtm3Vrl07LViwQOfOndPw4cM9HRoAAAAAH+T1RdJtt92mX375RVOmTNHRo0fVqlUrrVy5UjVq1PB0aFc8q9WqqVOnFro8EWWPXLsHeXYP8uw+5No9yLN7kGf3Idd/nlfPbgcAAAAA7ubV9yQBAAAAgLtRJAEAAACAA4okAAAAAHBAkQRcQnx8vBYsWFCqvkuXLnXb93IlJSWpVatWbtmWO3Tt2lXjxo2T5FrOUTaMMbrrrrtUrVo1WSwWpaWleTqkv4TExEQNGDDA02H8pVgsFr3//vueDgMl8LX3N1yZmLgB+P8tXbpU48aN0+nTp53af/nlF4WEhCg4OPiSY/z22286c+aMIiMjyzQ2i8WiZcuWOX2YOnv2rHJychQeHl6m2/KUrl27qlWrVlqwYIFLOS9vBw4cUO3atbVjxw6fftNesWKF+vfvr/Xr16tOnTqqXr26Klb0+glQr3hZWVkyxvCl525U1PEU3sXX3t/+DMf3xvKUmJio06dP8wcEB7wDokzZbDb5+/t7OowyFRERUeq+QUFBCgoKKsdo/p/Q0FCFhoa6ZVvu5krOUTb27dun6OhodezYsdy2kZubq4CAgHIb/0pUmm99B640l/u7boxRXl6eT7+/lbWCnPFHrbLH5XZXqJUrV+qaa65RlSpVFB4erhtuuEH79u2T9Mdfvi0Wi9577z1de+21Cg4OVsuWLbVp0yanMV544QXFxcUpODhYAwcO1Lx58wr9NfODDz7Q3/72NwUGBqpOnTqaNm2afv/9d/t6i8WixYsX68Ybb1RISIgef/zxcn/uxfkzOVm/fr2GDx+urKwsWSwWWSwWJSUlSSp86dfp06d19913q0aNGgoMDFSzZs20fPlySYUvtyu4ZOD555+35/rWW29VVlaWvc/WrVvVs2dPVa9eXZUrV1aXLl20fft2+/r4+HhJ0sCBA2WxWOzLF1+OkJ+fr+nTpys2NlZWq9X+nWIFSrtfuMO5c+c0dOhQhYaGKjo6Wk8++aTTesecG2OUlJSkmjVrymq1KiYmRmPHjrX3zczM1PXXX6+goCDVrl1bKSkpTo8veN6Ol4+dPn1aFotF69evlyT9+uuvuv322xUREaGgoCDVr19fycnJkqTatWtLklq3bi2LxaKuXbuWS048KTExUWPGjNGhQ4fs+1h+fr5mzpyp2rVrKygoSC1bttS7775rf0xeXp5GjBhhX9+wYUMtXLiw0LgDBgzQ448/rpiYGDVs2NDdT83rOV5ul5OTo7FjxyoyMlKBgYG65pprtHXrVkl//B7Uq1dPc+fOdXp8WlqaLBaLMjIy3B2627z77rtq3ry5goKCFB4erh49eujcuXOXPHZK0t69e9W5c2cFBgaqSZMmWrNmjdP60h4Xv/zyS/39739XUFCQ4uLiNHbsWJ07d86+/tlnn1X9+vUVGBioGjVq6Oabb75k/N6muDgdL4UuMGDAACUmJtqX4+PjNWPGDA0dOlRhYWG666677Ll966231LFjR/v7ZWpqqv1x69evl8Vi0YoVK9SmTRtZrVZ9+eWXhd7f1q9fr3bt2ikkJERVqlRRp06ddPDgQfv6S31WuVIlJiYqNTVVCxcutH82Wbp0aZE5K+rS3XHjxjm9ZxX3GiclJemVV17RBx98YN9OwfvjX5rBFendd981//vf/8zevXvNjh07TL9+/Uzz5s1NXl6e2b9/v5FkGjVqZJYvX27S09PNzTffbGrVqmVsNpsxxpgvv/zS+Pn5mSeeeMKkp6ebRYsWmWrVqpnKlSvbt/H555+bsLAws3TpUrNv3z6zevVqEx8fb5KSkux9JJnIyEjz8ssvm3379pmDBw+6OxV2fyYnOTk5ZsGCBSYsLMxkZmaazMxMc+bMGWOMMbVq1TLz5883xhiTl5dnOnToYJo2bWpWr15t9u3bZz766CPzySefGGOMSU5Odsrh1KlTTUhIiOnWrZvZsWOHSU1NNfXq1TNDhgyx91m3bp157bXXzJ49e8x3331nRowYYWrUqGGys7ONMcYcP37cSDLJyckmMzPTHD9+3D52y5Yt7ePMmzfPhIWFmTfffNN8//335qGHHjL+/v7mhx9+MMaYUu0X7nLvvfeamjVrmrVr15pdu3aZG264wVSqVMncf//9xhjnnL/zzjsmLCzMfPLJJ+bgwYNmy5YtZsmSJfaxevToYVq1amU2b95stm3bZrp06WKCgoLsjy943jt27LA/5tdffzWSzGeffWaMMWb06NGmVatWZuvWrWb//v1mzZo15sMPPzTGGPPVV18ZSWbt2rUmMzPTnDx5srzT43anT58206dPN7GxsfZ97LHHHjONGjUyK1euNPv27TPJycnGarWa9evXG2OMyc3NNVOmTDFbt241P/74o3n99ddNcHCwefvtt+3jDhs2zISGhpo77rjD7N692+zevdtTT9FrDRs2zPTv398YY8zYsWNNTEyM+eSTT8y3335rhg0bZqpWrWrf5x5//HHTpEkTp8ePHTvWdO7c2d1hu82RI0dMxYoVzbx588z+/fvNrl27zKJFi8yZM2cueezMy8szzZo1M927dzdpaWkmNTXVtG7d2kgyy5YtM8aU7riYkZFhQkJCzPz5880PP/xgNmzYYFq3bm0SExONMcZs3brVVKhQwaSkpJgDBw6Y7du3m4ULF14yfm9SUpxdunSxH5sL9O/f3wwbNsy+XKtWLRMWFmbmzp1rMjIyTEZGhj23sbGx5t133zXfffedufPOO02lSpXMiRMnjDHGfPbZZ0aSadGihVm9erXJyMgwJ0+edHp/s9lspnLlymbChAkmIyPDfPfdd2bp0qX2zxul+axypTp9+rRJSEgwI0eOtH82Wbt2bZE5czyWFLj//vtNly5djDElv8Znzpwxt956q+nTp499Ozk5Oe5/wl6GIslH/PLLL0aS+eabb+wHphdffNG+/ttvvzWSzJ49e4wxxtx2223m+uuvdxrj9ttvd/qA3717d/Of//zHqc9rr71moqOj7cuSzLhx48rhGf15rubk4gKngOMH9lWrVhk/Pz+Tnp5e5DaLKpIqVKhgfvrpJ3vbihUrjJ+fn8nMzCxyjLy8PFOpUiXz0Ucf2dsc39Qdx3YskmJiYszjjz/u1Ofqq682o0aNMsaYUuXAHc6cOWMCAgLMf//7X3vbyZMnTVBQUJFF0pNPPmkaNGhgcnNzC421Z88eI8ls3brV3rZ3714jyaUiqV+/fmb48OFFxlvU433R/PnzTa1atYwxxly4cMEEBwebjRs3OvUZMWKEGTx4cLFjjB492gwaNMi+PGzYMFOjRg3ebEtQ8MHm7Nmzxt/f37zxxhv2dbm5uSYmJsbMmTPHGGPMzz//bCpUqGC2bNliX1+9enWzdOlSj8TuDtu2bTOSzIEDBy7Z9+Jj56pVq0zFihXNzz//bO+zYsWKIoukko6LI0aMMHfddZfTtr744gvj5+dnfvvtN/O///3PhIWF2Yuzy43fk0qKs7RF0oABA5z6FOR21qxZ9jabzWZiY2PN7NmzjTH/r0h6//33nR7r+P528uRJI8n+B5qLleazypXs4vwXl7NLFUmX2heLevxfHZfbXaH27t2rwYMHq06dOgoLC7NfgnXo0CF7nxYtWtj/Hx0dLUk6fvy4JCk9PV3t2rVzGvPi5Z07d2r69On2a4NDQ0M1cuRIZWZm6vz58/Z+bdu2LdPndrn+bE5KIy0tTbGxsWrQoEGpH1OzZk1dddVV9uWEhATl5+crPT1dknTs2DGNHDlS9evXV+XKlRUWFqazZ886xX0p2dnZOnLkiDp16uTU3qlTJ+3Zs8ep7c/m4M/at2+fcnNz1b59e3tbtWrVir0U65ZbbtFvv/2mOnXqaOTIkVq2bJn9Mor09HRVrFhRf/vb3+z969Wrp6pVq7oU07333qu33npLrVq10kMPPaSNGzdexjPzHRkZGTp//rx69uzp9Pv/6quv2i9hlaRFixapTZs2ioiIUGhoqJYsWVJov23evDn3IZXCvn37ZLPZnH6H/f391a5dO/vvcExMjK6//nq9/PLLkqSPPvpIOTk5uuWWWzwSszu0bNlS3bt3V/PmzXXLLbfohRde0K+//irp0sfOPXv2KC4uTjExMfbxEhISitxOScfFnTt3aunSpU6/C71791Z+fr7279+vnj17qlatWqpTp47uuOMOvfHGG/b3yJLi9yZlEWdxnwUcc16xYkW1bdu20PtSSZ8jqlWrpsTERPXu3Vv9+vXTwoULlZmZaV9f2s8qvsbVz15Xyr7oTSiSrlD9+vXTqVOn9MILL2jLli3asmWLpD9ulizgOIGCxWKR9Md9K6V19uxZTZs2TWlpafafb775Rnv37lVgYKC9X0hIyJ99OmXCHTkpj0kZhg0bprS0NC1cuFAbN25UWlqawsPDneIuS382B+4WFxen9PR0PfvsswoKCtKoUaPUuXNn2Wy2Uj3ez++Pw5xxmMjz4sf27dtXBw8e1AMPPKAjR46oe/fumjBhQtk9iSvM2bNnJUkff/yx0+//d999Z78v6a233tKECRM0YsQIrV69WmlpaRo+fHih/dZbjg++4s4779Rbb72l3377TcnJybrtttu8YhbI8lKhQgWtWbNGK1asUJMmTfT000+rYcOG2r9/f5keO0s6Lp49e1Z333230+/Czp07tXfvXtWtW1eVKlXS9u3b9eabbyo6OlpTpkxRy5Ytdfr06RLj9yYlxenn5+d0/JQKH0OlP/e7fqnHJicna9OmTerYsaPefvttNWjQQJs3b5ZU+s8qvubinF3qdbpS9kVvQpF0BTp58qTS09P16KOPqnv37mrcuLHLfw1o2LCh/YbgAhcv/+1vf1N6errq1atX6Kfgg6e3KIucBAQEKC8vr8Q+LVq00E8//aQffvih1OMeOnRIR44csS9v3rxZfn5+9jMnGzZs0NixY3XdddepadOmslqtOnHihNMY/v7+JcYWFhammJgYbdiwwal9w4YNatKkSaljdYe6devK39/fXsRKf0ycUFJOg4KC1K9fPz311FNav369Nm3apG+++UYNGzbU77//rh07dtj7ZmRkOL32BTPlOf7lsajvAIqIiNCwYcP0+uuva8GCBVqyZIkk2c+CXGrf8CVNmjSR1WrVoUOHCv3ux8XFSfpj3+rYsaNGjRql1q1bq169ek5nmeCaunXrKiAgwOl32GazaevWrU6/w9ddd51CQkK0ePFirVy5Uv/61788Ea5bWSwWderUSdOmTdOOHTsUEBCgZcuWXfLY2bhxYx0+fNjpd7/gg7Ur/va3v+m7774r8r2w4PhQsWJF9ejRQ3PmzNGuXbt04MABffrppyXG722KizMiIsIph3l5edq9e3epx3XM+e+//65t27apcePGLsfXunVrTZo0SRs3blSzZs2UkpIi6cr6rHI5SvPZRFKh10kq/F5X0r5Y2u38lTBf4BWoatWqCg8P15IlSxQdHa1Dhw7p3//+t0tjjBkzRp07d9a8efPUr18/ffrpp1qxYoX9L2iSNGXKFN1www2qWbOmbr75Zvn5+Wnnzp3avXu3HnvssbJ+Wn9KWeQkPj5eZ8+e1bp169SyZUsFBwcX+gttly5d1LlzZw0aNEjz5s1TvXr19P3338tisahPnz5FjhsYGKhhw4Zp7ty5ys7O1tixY3XrrbcqKipKklS/fn299tpratu2rbKzszVx4sRCZ6zi4+O1bt06derUSVartcjLySZOnKipU6eqbt26atWqlZKTk5WWlqY33njDpTyUt9DQUI0YMUITJ05UeHi4IiMj9cgjjxT7ZrZ06VLl5eWpffv2Cg4O1uuvv66goCDVqlXLPjvPXXfdpcWLF8vf318PPviggoKC7PtyUFCQOnTooFmzZql27do6fvy4Hn30UadtTJkyRW3atFHTpk2Vk5Oj5cuX29/EIyMjFRQUpJUrVyo2NlaBgYE+P21zpUqVNGHCBD3wwAPKz8/XNddco6ysLG3YsEFhYWEaNmyY6tevr1dffVWrVq1S7dq19dprr2nr1q322QDhmpCQEN17772aOHGiqlWrppo1a2rOnDk6f/68RowYYe9XoUIFJSYmatKkSapfv36xl4/5ii1btmjdunXq1auXIiMjtWXLFv3yyy9q3LjxJY+dPXr0UIMGDTRs2DA98cQTys7O1iOPPOJyDA8//LA6dOig++67T3feeadCQkL03Xffac2aNXrmmWe0fPly/fjjj+rcubOqVq2qTz75RPn5+WrYsGGJ8XuTkuIMCQnR+PHj9fHHH6tu3bqaN29eoe8TLMmiRYtUv359NW7cWPPnz9evv/7qUnG/f/9+LVmyRDfeeKNiYmKUnp6uvXv3aujQoZKurM8qlyM+Pl5btmzRgQMHFBoaWuyVH926ddMTTzyhV199VQkJCXr99de1e/dutW7dWlLJr3HBdlatWqX09HSFh4ercuXKPveVLi7z8D1RuExr1qwxjRs3Nlar1bRo0cKsX7/efjNqaW5UN8aYJUuWmKuuusoEBQWZAQMGmMcee8xERUU5bWflypWmY8eOJigoyISFhZl27do5zSymIiYU8JSyyMk999xjwsPDjSQzdepUY4zzJALG/HET6fDhw014eLgJDAw0zZo1M8uXLzfGFD1xQ8uWLc2zzz5rYmJiTGBgoLn55pvNqVOn7H22b99u2rZtawIDA039+vXNO++8U2ibH374oalXr56pWLGi/eb6iyduyMvLM0lJSeaqq64y/v7+pmXLlmbFihX29aXNgTucOXPG/POf/zTBwcGmRo0aZs6cOU43pzo+/2XLlpn27dubsLAwExISYjp06GDWrl1rH+vIkSOmb9++xmq1mlq1apmUlBQTGRlpnnvuOXuf7777ziQkJJigoCDTqlUrs3r1aqfnPWPGDNO4cWMTFBRkqlWrZvr3729+/PFH++NfeOEFExcXZ/z8/Ow3wfoax4kbjDEmPz/fLFiwwDRs2ND4+/ubiIgI07t3b5OammqM+WNyh8TERFO5cmVTpUoVc++995p///vfTvskNwJfmmOOfvvtNzNmzBhTvXp1Y7VaTadOncxXX31V6DH79u0zkuwTOviy7777zvTu3dtEREQYq9VqGjRoYJ5++mljTOmOnenp6eaaa64xAQEBpkGDBmblypVFTtxwqePiV199ZXr27GlCQ0NNSEiIadGihX2inC+++MJ06dLFVK1a1QQFBZkWLVrYZ3ksKX5vUlKcubm55t577zXVqlUzkZGRZubMmUVO3OCYd2P+X25TUlJMu3btTEBAgGnSpIn59NNP7X0KJiH49ddfnR7r+P529OhRM2DAABMdHW0CAgJMrVq1zJQpU0xeXp69/6U+q1zJ0tPTTYcOHUxQUJB9ptuicmaMMVOmTDE1atQwlStXNg888IC577777O9Zl9oXjx8/bt/HPfG5wBtZjLnoAkb8ZY0cOVLff/+9vvjiC0+H4jOSkpL0/vvvF3l5F8rHTz/9pLi4OK1du1bdu3f3dDhAiQYPHqwKFSro9ddfL/VjvvjiC3Xv3l2HDx9WjRo1yjE64PIdOHBAtWvX1o4dO5y+8wi4UnC53V/Y3Llz1bNnT4WEhGjFihV65ZVX9Oyzz3o6LMAln376qc6ePavmzZsrMzNTDz30kOLj49W5c2dPhwYU6/fff9cPP/ygTZs26e677y7VY3JycvTLL78oKSlJt9xyCwUSAJSjK/+ONly2r776Sj179lTz5s313HPP6amnntKdd97p6bAAl9hsNv3f//2fmjZtqoEDByoiIkLr16/nWmp4td27d6tt27Zq2rSp7rnnnlI95s0331StWrV0+vRpzZkzp5wjBIC/Ni63AwAAAAAHnEkCAAAAAAcUSQAAAADggCIJAAAAABxQJAEAAACAA4okAAAAAHBAkQQAgP748me+9BIAIFEkAQA8KDExURaLpdBPnz59ynW7FotF77//vlPbhAkTtG7dunLdLgDgylDR0wEAAP7a+vTpo+TkZKc2q9Xq9jhCQ0MVGhrq9u0CALwPZ5IAAB5ltVoVFRXl9FO1alVJf5zxef7553XDDTcoODhYjRs31qZNm5SRkaGuXbsqJCREHTt21L59+5zGXLx4serWrauAgAA1bNhQr732mn1dfHy8JGngwIGyWCz25Ysvt8vPz9f06dMVGxsrq9WqVq1aaeXKlfb1Bw4ckMVi0Xvvvadrr71WwcHBatmypTZt2lQ+iQIAuA1FEgDAq82YMUNDhw5VWlqaGjVqpCFDhujuu+/WpEmT9PXXX8sYo/vuu8/ef9myZbr//vv14IMPavfu3br77rs1fPhwffbZZ5KkrVu3SpKSk5OVmZlpX77YwoUL9eSTT2ru3LnatWuXevfurRtvvFF79+516vfII49owoQJSktLU4MGDTR48GD9/vvv5ZQNAIA7UCQBADxq+fLl9kvdCn7+85//2NcPHz5ct956qxo0aKCHH35YBw4c0O23367evXurcePGuv/++7V+/Xp7/7lz5yoxMVGjRo1SgwYNNH78eN10002aO3euJCkiIkKSVKVKFUVFRdmXLzZ37lw9/PDD+sc//qGGDRtq9uzZatWqlRYsWODUb8KECbr++uvVoEEDTZs2TQcPHlRGRkbZJgkA4FYUSQAAj7r22muVlpbm9HPPPffY17do0cL+/xo1akiSmjdv7tR24cIFZWdnS5L27NmjTp06OW2jU6dO2rNnT6ljys7O1pEjR0o1jmN80dHRkqTjx4+XelsAAO/DxA0AAI8KCQlRvXr1il3v7+9v/7/FYim2LT8/v5wiLJk3xQIAKBucSQIA+JTGjRtrw4YNTm0bNmxQkyZN7Mv+/v7Ky8srdoywsDDFxMRcchwAgG/iTBIAwKNycnJ09OhRp7aKFSuqevXqlzXexIkTdeutt6p169bq0aOHPvroI7333ntau3atvU98fLzWrVunTp06yWq12mfTu3icqVOnqm7dumrVqpWSk5OVlpamN95447LiAgBcOSiSAAAetXLlSvu9PAUaNmyo77///rLGGzBggBYuXKi5c+fq/vvvV+3atZWcnKyuXbva+zz55JMaP368XnjhBV111VU6cOBAoXHGjh2rrKwsPfjggzp+/LiaNGmiDz/8UPXr17+suAAAVw6LMcZ4OggAAAAA8BbckwQAAAAADiiSAAAAAMABRRIAAAAAOKBIAgAAAAAHFEkAAAAA4IAiCQAAAAAcUCQBAAAAgAOKJAAAAABwQJEEAAAAAA4okgAAAADAAUUSAAAAADj4/wDOgGxQkHB3BAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "labels = emotion_df['target_emotion'].unique()\n",
    "post_total = len(emotion_df)\n",
    "df1 = emotion_df.groupby(['target_emotion']).count()['tweet_id']\n",
    "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plt.bar(df1.index,df1.values)\n",
    "\n",
    "#arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets seem to be biased towards joyful feelings. This is great in the sense that our dataset is dominated by positive feelings but bad for our model since the classes are quite unbalanced. We will sample our dataset to have a more balanced number of examples and use this reduced training dataset to train our model. We first shuffle our dataset and then sample it accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>hashtag_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "      <th>target_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461576</th>\n",
       "      <td>0x258855</td>\n",
       "      <td>@ewnreporter Highly favoured by God...#blessed...</td>\n",
       "      <td></td>\n",
       "      <td>2015-05-01 14:10:17</td>\n",
       "      <td>856</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800903</th>\n",
       "      <td>0x2c2e95</td>\n",
       "      <td>I hated school, but I miss it now. &lt;LH&gt;</td>\n",
       "      <td></td>\n",
       "      <td>2017-02-08 14:26:27</td>\n",
       "      <td>845</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311642</th>\n",
       "      <td>0x2298d1</td>\n",
       "      <td>@NARAL @SenSchumer &lt;LH&gt; on the #GOP for being ...</td>\n",
       "      <td>GOP</td>\n",
       "      <td>2015-11-15 13:09:35</td>\n",
       "      <td>283</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21075</th>\n",
       "      <td>0x1ce918</td>\n",
       "      <td>@Uber no one has still gotten back to me over ...</td>\n",
       "      <td>neglect badcustomerservice</td>\n",
       "      <td>2015-10-05 13:15:38</td>\n",
       "      <td>351</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264842</th>\n",
       "      <td>0x21ae69</td>\n",
       "      <td>@CNN &lt;LH&gt; For real sad. This is why we need to...</td>\n",
       "      <td></td>\n",
       "      <td>2015-11-26 07:02:41</td>\n",
       "      <td>971</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                                         tweet_text  \\\n",
       "461576  0x258855  @ewnreporter Highly favoured by God...#blessed...   \n",
       "800903  0x2c2e95            I hated school, but I miss it now. <LH>   \n",
       "311642  0x2298d1  @NARAL @SenSchumer <LH> on the #GOP for being ...   \n",
       "21075   0x1ce918  @Uber no one has still gotten back to me over ...   \n",
       "264842  0x21ae69  @CNN <LH> For real sad. This is why we need to...   \n",
       "\n",
       "                      hashtag_text           crawl_date score target_emotion  \n",
       "461576                              2015-05-01 14:10:17   856            joy  \n",
       "800903                              2017-02-08 14:26:27   845            joy  \n",
       "311642                         GOP  2015-11-15 13:09:35   283        disgust  \n",
       "21075   neglect badcustomerservice  2015-10-05 13:15:38   351        disgust  \n",
       "264842                              2015-11-26 07:02:41   971        sadness  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Let's shuffle the dataset first\n",
    "train_df = train_df.sample(frac=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let's sample out train dataset with n = 39867 since it is the minimum number of examples found in one of the classes (anger). \n",
    "rtrain_df = train_df.groupby(\"target_emotion\").sample(n=60000, random_state=42, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtrain_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_emotion\n",
       "anger           60000\n",
       "anticipation    60000\n",
       "disgust         60000\n",
       "fear            60000\n",
       "joy             60000\n",
       "sadness         60000\n",
       "surprise        60000\n",
       "trust           60000\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtrain_df.groupby(['target_emotion']).count()['tweet_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our classes are more balanced. Then, we notice that some of the hashtag text columns entries are empty. Since they contain valuable information, we don't want to drop them. Instead, we could add them to the *tweet_text* column and then drop the *hashtag_text* column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###First cast the hashtag text column as string\n",
    "rtrain_df['hashtag_text'] = rtrain_df['hashtag_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Next, we add the hashtag_text to the tweet_text column \n",
    "rtrain_df['tweet_text'] = rtrain_df['tweet_text'] + rtrain_df['hashtag_text']\n",
    "rtrain_df['tweet_text'] = rtrain_df['tweet_text'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Finally, drop the hashtag_text column\n",
    "rtrain_df.drop('hashtag_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 480000 entries, 227758 to 796533\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   tweet_id        480000 non-null  string\n",
      " 1   tweet_text      479999 non-null  string\n",
      " 2   crawl_date      480000 non-null  object\n",
      " 3   score           480000 non-null  object\n",
      " 4   target_emotion  480000 non-null  object\n",
      "dtypes: object(3), string(2)\n",
      "memory usage: 217.0 MB\n"
     ]
    }
   ],
   "source": [
    "rtrain_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the *tweet_text* column has some symbols such as '#','@' or '< LH >'. We want to remove them as they are irrelevant. We preprocess the *tweet_text* column below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrain_df['tweet_text'] = rtrain_df['tweet_text'].map(lambda x: str(x).replace('#',''))\n",
    "rtrain_df['tweet_text'] = rtrain_df['tweet_text'].map(lambda x: str(x).replace('@',''))\n",
    "rtrain_df['tweet_text'] = rtrain_df['tweet_text'].map(lambda x: str(x).replace('<LH>',''))\n",
    "\n",
    "def removeLinks(text):\n",
    "    return re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text)\n",
    "\n",
    "rtrain_df['tweet_text'] = rtrain_df['tweet_text'].apply(removeLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "      <th>target_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065862</th>\n",
       "      <td>0x315f47</td>\n",
       "      <td>31 Push the  everyday. Be some special.  Novem...</td>\n",
       "      <td>2017-07-06 09:15:08</td>\n",
       "      <td>380</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52817</th>\n",
       "      <td>0x1d8812</td>\n",
       "      <td>We have Never had a President who picked fight...</td>\n",
       "      <td>2016-01-20 18:16:33</td>\n",
       "      <td>609</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474980</th>\n",
       "      <td>0x25cbaf</td>\n",
       "      <td>PsychologyDoc Goes to show how a little love c...</td>\n",
       "      <td>2017-05-03 22:11:38</td>\n",
       "      <td>565</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504270</th>\n",
       "      <td>0x265e8d</td>\n",
       "      <td>Essex_CC wait 20 mins for a bus cos your board...</td>\n",
       "      <td>2015-09-12 11:44:50</td>\n",
       "      <td>420</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345488</th>\n",
       "      <td>0x2341ca</td>\n",
       "      <td>is just a fiction people stupidly  to be real...</td>\n",
       "      <td>2015-03-21 07:37:43</td>\n",
       "      <td>354</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569792</th>\n",
       "      <td>0x27a70b</td>\n",
       "      <td>.WeWork proving to us that technology, design ...</td>\n",
       "      <td>2015-07-05 17:10:40</td>\n",
       "      <td>198</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605255</th>\n",
       "      <td>0x285923</td>\n",
       "      <td>My cat just coughed up a pubic hairball....  1...</td>\n",
       "      <td>2017-06-18 23:53:01</td>\n",
       "      <td>617</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719919</th>\n",
       "      <td>0x2a97f3</td>\n",
       "      <td>a bit feel depressed imagining-entering doctor...</td>\n",
       "      <td>2015-01-13 03:19:12</td>\n",
       "      <td>783</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249699</th>\n",
       "      <td>0x21624a</td>\n",
       "      <td>joeltelling apyrodesign Adobe AdobeAE Not inst...</td>\n",
       "      <td>2015-09-14 12:50:46</td>\n",
       "      <td>720</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366801</th>\n",
       "      <td>0x37419e</td>\n",
       "      <td>WatchMojo KIDNAPPED !! |    😦</td>\n",
       "      <td>2016-01-11 09:35:44</td>\n",
       "      <td>26</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                         tweet_text  \\\n",
       "1065862  0x315f47  31 Push the  everyday. Be some special.  Novem...   \n",
       "52817    0x1d8812  We have Never had a President who picked fight...   \n",
       "474980   0x25cbaf  PsychologyDoc Goes to show how a little love c...   \n",
       "504270   0x265e8d  Essex_CC wait 20 mins for a bus cos your board...   \n",
       "345488   0x2341ca   is just a fiction people stupidly  to be real...   \n",
       "569792   0x27a70b  .WeWork proving to us that technology, design ...   \n",
       "605255   0x285923  My cat just coughed up a pubic hairball....  1...   \n",
       "719919   0x2a97f3  a bit feel depressed imagining-entering doctor...   \n",
       "249699   0x21624a  joeltelling apyrodesign Adobe AdobeAE Not inst...   \n",
       "1366801  0x37419e                     WatchMojo KIDNAPPED !! |    😦    \n",
       "\n",
       "                  crawl_date score target_emotion  \n",
       "1065862  2017-07-06 09:15:08   380            joy  \n",
       "52817    2016-01-20 18:16:33   609        sadness  \n",
       "474980   2017-05-03 22:11:38   565       surprise  \n",
       "504270   2015-09-12 11:44:50   420          anger  \n",
       "345488   2015-03-21 07:37:43   354        sadness  \n",
       "569792   2015-07-05 17:10:40   198       surprise  \n",
       "605255   2017-06-18 23:53:01   617        sadness  \n",
       "719919   2015-01-13 03:19:12   783           fear  \n",
       "249699   2015-09-14 12:50:46   720           fear  \n",
       "1366801  2016-01-11 09:35:44    26       surprise  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtrain_df = rtrain_df.sample(frac=1)\n",
    "rtrain_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's explore a Decision Tree model and test the model performance in Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480000, 5000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_5000 = CountVectorizer(max_features=5000, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_5000.fit(rtrain_df['tweet_text'])\n",
    "\n",
    "train_data_BOW_features_5000 = BOW_5000.transform(rtrain_df['tweet_text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_5000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if emojis are present in our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_5000 = BOW_5000.get_feature_names_out()\n",
    "\"😂\" in feature_names_5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (480000, 5000)\n",
      "y_train.shape:  (480000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train = train_data_BOW_features_5000\n",
    "y_train = rtrain_df['target_emotion']\n",
    "\n",
    "##Let's take a look at the dimensions\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "## Build the DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "## Train the model\n",
    "DT_model = DT_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the performance of our classifier in Kaggle. Let's create a test dataframe from the test.csv file and clean it as we did with the r_train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/_jd53fqs7hn9l98yc6xmfh040000gn/T/ipykernel_96340/844371213.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_df = pd.read_csv(\"./test.csv\",header=None, names=['tweet_id','tweet_text','hashtag_text','crawl_date','score'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>hashtag_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "      <td></td>\n",
       "      <td>2017-01-17 14:13:32</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "      <td></td>\n",
       "      <td>2015-10-17 06:46:20</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
       "      <td>womendrivers</td>\n",
       "      <td>2016-12-19 03:50:27</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>@cineworld “only the brave” just out and fount...</td>\n",
       "      <td>robbingmembers</td>\n",
       "      <td>2017-04-09 19:32:19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>Felt like total dog 💩 going into open gym and ...</td>\n",
       "      <td></td>\n",
       "      <td>2016-01-15 11:59:31</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                         tweet_text  \\\n",
       "1  0x28cc61  @Habbo I've seen two separate colours of the e...   \n",
       "2  0x2db41f  @FoxNews @KellyannePolls No serious self respe...   \n",
       "3  0x2466f6  Looking for a new car, and it says 1 lady owne...   \n",
       "4  0x23f9e9  @cineworld “only the brave” just out and fount...   \n",
       "5  0x1fb4e1  Felt like total dog 💩 going into open gym and ...   \n",
       "\n",
       "     hashtag_text           crawl_date score  \n",
       "1                  2017-01-17 14:13:32   107  \n",
       "2                  2015-10-17 06:46:20   728  \n",
       "3    womendrivers  2016-12-19 03:50:27   491  \n",
       "4  robbingmembers  2017-04-09 19:32:19    28  \n",
       "5                  2016-01-15 11:59:31   925  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./test.csv\",header=None, names=['tweet_id','tweet_text','hashtag_text','crawl_date','score'])\n",
    "test_df.drop([0], inplace = True); #Drop the header\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>Habbo I've seen two separate colours of the el...</td>\n",
       "      <td>2017-01-17 14:13:32</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>FoxNews KellyannePolls No serious self respect...</td>\n",
       "      <td>2015-10-17 06:46:20</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
       "      <td>2016-12-19 03:50:27</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>cineworld “only the brave” just out and founta...</td>\n",
       "      <td>2017-04-09 19:32:19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>Felt like total dog 💩 going into open gym and ...</td>\n",
       "      <td>2016-01-15 11:59:31</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                         tweet_text  \\\n",
       "1  0x28cc61  Habbo I've seen two separate colours of the el...   \n",
       "2  0x2db41f  FoxNews KellyannePolls No serious self respect...   \n",
       "3  0x2466f6  Looking for a new car, and it says 1 lady owne...   \n",
       "4  0x23f9e9  cineworld “only the brave” just out and founta...   \n",
       "5  0x1fb4e1  Felt like total dog 💩 going into open gym and ...   \n",
       "\n",
       "            crawl_date score  \n",
       "1  2017-01-17 14:13:32   107  \n",
       "2  2015-10-17 06:46:20   728  \n",
       "3  2016-12-19 03:50:27   491  \n",
       "4  2017-04-09 19:32:19    28  \n",
       "5  2016-01-15 11:59:31   925  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Clean the test dataset \n",
    "test_df['tweet_text'] = test_df['tweet_text'].astype('string') + test_df['hashtag_text'].astype('string')\n",
    "test_df.drop('hashtag_text', axis=1, inplace=True)\n",
    "test_df['tweet_text'] = test_df['tweet_text'].map(lambda x: x.replace('#',''))\n",
    "test_df['tweet_text'] = test_df['tweet_text'].map(lambda x: x.replace('@',''))\n",
    "test_df['tweet_text'] = test_df['tweet_text'].map(lambda x: x.replace('<LH>',''))\n",
    "\n",
    "test_df['tweet_text'] = test_df['tweet_text'].apply(removeLinks)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Declare X_test and transform it\n",
    "X_test = BOW_5000.transform(test_df['tweet_text'])\n",
    "\n",
    "###Make an initial prediction \n",
    "y_test_pred = DT_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['disgust', 'sadness', 'sadness', 'trust', 'anticipation', 'joy',\n",
       "       'trust', 'joy', 'disgust', 'disgust', 'surprise', 'joy', 'sadness',\n",
       "       'disgust', 'trust', 'joy', 'surprise', 'anticipation', 'surprise',\n",
       "       'trust'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write these results to a *submission* csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeSubmissionCSV(test_df, y_test_pred):\n",
    "    #Open the train.csv and test.csv in writing mode\n",
    "    sub_file = open(\"./submission.csv\", 'w', newline='');\n",
    "    sub_writer = csv.writer(sub_file);\n",
    "\n",
    "    #Write the header\n",
    "    header = ['id','emotion'];\n",
    "    sub_writer.writerow(header); \n",
    "\n",
    "    #Convert the test_df tweet id column to a list\n",
    "    tweet_ids = test_df['tweet_id'].to_list();\n",
    "\n",
    "    #Write to the CSV file \n",
    "    data = [];\n",
    "    count = 0;\n",
    "    for id in tweet_ids:\n",
    "        data = [id, y_test_pred[count]]\n",
    "        sub_writer.writerow(data);\n",
    "        count+=1\n",
    "        data = []\n",
    "\n",
    "    #Close the CSV file \n",
    "    sub_file.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **-----------DT MODEL KAGGLE SCORE: 0.23571--------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a random forest classifier now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a model with defined parameters\n",
    "rf_class = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Fit the vectorized train set to the model\n",
    "rf_model = rf_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predict\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'disgust', 'trust', 'joy', 'disgust', 'joy', 'trust',\n",
       "       'sadness', 'anticipation', 'sadness'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeSubmissionCSV(test_df, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
